{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80b2f999",
   "metadata": {},
   "source": [
    "# Obtaining structured web content and programmatic access\n",
    "\n",
    "In this notebook we will learn how to make use of readily structured data through dedicated application programming interfaces (APIs), how to authenticate and how to properly design requests (also called \"payload\") in order to retrieve large datasets.\n",
    "\n",
    "**Advantages** of APIs are that\n",
    "- access is legal and in most cases clearly and transparently regulated (e.g. 10,000 calls per day)\n",
    "- structuring through `requests` and `BeautifulSoup` not required\n",
    "- Python packages that simplify server-client interaction are available\n",
    "\n",
    "**Disadvantages** of APIs are that\n",
    "- we have to learn how APIs work and how we should interact with them (each API has some peculiarities and documentation is usually good, but sometimes not so...)\n",
    "- authentification may be required and access may not be free of charge \n",
    "\n",
    "We will\n",
    "- obtain data of a public statistical office such as the IMF or World Bank through the `pandas-datareader`\n",
    "- directly obtain a (ranking) table from a website such the [World Cube Association](https://www.worldcubeassociation.org/results/rankings/333/single)\n",
    "- learn how to use the Destatis/GENESIS Online service and API\n",
    "- learn how to use the Twitter API (in particular [Tweepy](https://www.tweepy.org/), a Python library for the Twitter API) and retrieve Tweets with GeoTags (i.e. coordinates) subject to specified geography and search terms\n",
    "- conduct some small analyses and visualise the results appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3887aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada2bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas-datareader --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d12ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import wb # imports world bank access\n",
    "search = wb.search('GDP.*current.*US') # search for keyword\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf9b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wb.download(indicator = 'NY.GDP.MKTP.CD', country = ['DE', 'FR', 'IT'],\n",
    "                start = 2000, end = 2019)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4e4736",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('country').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384fc7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.reset_index()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca64ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c215845",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns = ['country', 'year', 'gdp'] # rename columns\n",
    "df2.year = df2.year.astype(int) # numeric annual indicator\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508004fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a18cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(df2['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d253cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "\n",
    "for country in df2['country'].unique():\n",
    "    \n",
    "    trace = go.Scatter(name = country, x = df2[df2['country'] == country]['year'],\n",
    "                      y = df2[df2['country'] == country]['gdp'])\n",
    "    \n",
    "    traces.append(trace)\n",
    "    \n",
    "fig = go.Figure(data = traces)\n",
    "\n",
    "fig.layout.update(title=go.layout.Title(\n",
    "\n",
    "    text = 'Nominal GDP'\n",
    "\n",
    "))\n",
    "\n",
    "fig.layout.update(yaxis= go.layout.YAxis(title=go.layout.yaxis.Title(\n",
    "                        text='in US$')));\n",
    "\n",
    "fig.layout.update(xaxis = go.layout.XAxis(title = go.layout.xaxis.Title(text = 'Year'), rangeslider = dict(visible = True)));\n",
    "\n",
    "iplot(fig, filename = 'Nominal_GDP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db659726",
   "metadata": {},
   "source": [
    "## Directly parsing `table` objects from HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f036fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = pd.read_html('https://www.worldcubeassociation.org/results/rankings/333/single', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb241497",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f36c7d8",
   "metadata": {},
   "source": [
    "Which nationality appears most frequently in the World Cube Association's ranking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff69671",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking[0].groupby('Citizen of').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0feec9",
   "metadata": {},
   "source": [
    "Which nationality needed, on average, the **lowest** amount of time to solve a 3x3x3 cube? Sort the output in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee8ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking[0].groupby('Citizen of').mean()['Result'].sort_values(ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b05d4e",
   "metadata": {},
   "source": [
    "How many possible states/permutations, starting from the solved state, can a 3x3x3 Rubik's cube have? \n",
    "\n",
    "Hints:\n",
    "1. The centre squares are fixed (a plane rotation around these squares doesn't change the cube's state)\n",
    "2. There are eight corner pieces (with three colors on the side) and twelve edge pieces (with two colors on the side) which all revolve around the centre pieces\n",
    "3. There are six different colors\n",
    "4. We only look at \"legal\" states, i.e. those that can only be realised without assembling the cube (and therefore not violating Hint 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a151c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "answer = (math.factorial(8) * 3**8) * 1/3 * (math.factorial(12) * 2**12) * 1/2 * 1/2\n",
    "\n",
    "# [(corner pieces) * fraction of admissible corner combinations (clock-wise and anti-clockwise twists cancel each other out, \n",
    "# hence 3**7 / 3**8 = 1/3)] \n",
    "# * [(edge pieces) * fraction of admissible edge combinations (clock-wise and anti-clockwise twists cancel each other out, \n",
    "# hence 2**11 / 2**12 = 1/2)]\n",
    "# * [1/2 (only half of the corner and edge states can be reached as corner and edge states must both coincide in the number\n",
    "# i.e. even or odd of turns taken to reach either position)]\n",
    "\n",
    "print(str(answer) + \" or about 43.2 quintillion combinations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5cb0c7",
   "metadata": {},
   "source": [
    "Which result entry in the World Ranking table is the most recent one? Which one is the oldest one? Be as precise as possible! (Hint: You may have to combine your knowledge from scraping HTML files.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88da521b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1cc5c57",
   "metadata": {},
   "source": [
    "Compute the expected value of `Result` conditional on `Nationality = 'Germany'`. Are the German contestants statistically significantly faster/slower in solving the cube than other contestants, based on `Nationality`? Does statistical significance change if you use robust standard errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c58a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877dc566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffd1086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ranking[0]\n",
    "df['Non_German_Dummy'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41085005",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_german_index = df[df['Citizen of'] != 'Germany'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1aee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "german_index = [x for x in df.index if x not in non_german_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dabead",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_values = [0 if y in german_index else 1 for y in df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dummy_values\n",
    "Y = df['Result']\n",
    "\n",
    "X = sm.add_constant(X) # adding a constant\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5475a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_robustcov_results(cov_type='HC1').summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d97ad7",
   "metadata": {},
   "source": [
    "## Spatial libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b5f654",
   "metadata": {},
   "source": [
    "The installation procedure of spatial libraries for Python (on Windows) can be quite tedious but [this answer](https://stackoverflow.com/questions/51095970/install-python-geopandas-failed/51560940#51560940) on Stackoverflow (make sure to upvote ;)) and [this detailed instruction](https://geoffboeing.com/2014/09/using-geopandas-windows/) make it straight forward. You can also find the required wheels for Python 3.8 and 64-bit for offline `pip install` in this notebook's [repository](https://github.com/gerwolf/webscraping-workshop/tree/main/DataFrames%20and%20APIs). After this, you can simply `pip install geopandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea38be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = [16,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f356557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a78ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "world.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b25bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "world.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c258623",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://gist.githubusercontent.com/gerwolf/81ebb170eb25d4a13f2695db4520f90e/raw/7c24eb4a2b11f6d4c7ac38bdf3555dfc7da6823e/GDPpc_PPP.csv\", sep = \";\")\n",
    "df['Country'] = df['Country'].str.replace('�',' ')\n",
    "df['Country'] = df['Country'].str.replace('United States','United States of America')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeb33b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Country'] == 'United States of America']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5408903",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_geodf = df.merge(world, left_on='Country', right_on = 'name', how = 'left').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_geodf['GDPpc_PPP'] = final_geodf['GDPpc_PPP'].str.replace(',','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ffc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Choropleth(\n",
    "    locations=final_geodf['iso_a3'], # Spatial coordinates\n",
    "    z = final_geodf['GDPpc_PPP'].astype(float), # Data to be color-coded\n",
    "#     locationmode = 'world', # set of locations match entries in `locations`\n",
    "    colorscale = 'Reds',\n",
    "    text=final_geodf['Country']\n",
    "#     colorbar_title = \"Millions USD\",\n",
    ")])\n",
    "\n",
    "fig.layout.update(\n",
    "    title_text = 'GDP per capita (2018, IMF)',\n",
    "    geo_scope='world', # limite map scope to USA\n",
    ");\n",
    "\n",
    "iplot(fig, filename =\"geomap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45387e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Choropleth(\n",
    "    locations=final_geodf[final_geodf['continent'] == 'Europe']['iso_a3'], # Spatial coordinates\n",
    "    z = final_geodf[final_geodf['continent'] == 'Europe']['GDPpc_PPP'].astype(float), # Data to be color-coded\n",
    "#     locationmode = 'world', # set of locations match entries in `locations`\n",
    "    colorscale = 'Reds',\n",
    "    text=final_geodf[final_geodf['continent'] == 'Europe']['Country']\n",
    "#     colorbar_title = \"Millions USD\",\n",
    ")])\n",
    "\n",
    "fig.layout.update(\n",
    "    title_text = 'GDP per capita (2018, IMF)',\n",
    "    geo_scope='europe', # limite map scope to USA\n",
    ");\n",
    "\n",
    "iplot(fig, filename =\"geomap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838ac263",
   "metadata": {},
   "source": [
    "## Destatis/GENESIS Online\n",
    "The GENESIS API is the web interface service by the Federal Statistical Office of Germany and is a good place to start learning how to interact programmatically with a server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c20c927",
   "metadata": {},
   "source": [
    "There is a [comprehensive description/introduction](https://www-genesis.destatis.de/genesis/misc/GENESIS-Webservices_Einfuehrung.pdf) on the service, unfortunately in German only. To display the PDF inside Jupyter Notebook in Chrome you may have to enable the [PDF Viewer extension](https://chrome.google.com/webstore/detail/pdf-viewer/oemmndcbldboiebfnladdacbdfmadadm?utm_source=chrome-ntp-icon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a8769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame, display\n",
    "filepath = \"https://www-genesis.destatis.de/genesis/misc/GENESIS-Webservices_Einfuehrung.pdf\"\n",
    "IFrame(filepath, width=980, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6667a14f",
   "metadata": {},
   "source": [
    "Read about the `whoami` method (in Section 2.2). Do you have to authenticate? What does it return? How would you send a `request`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cfbd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import genesis_config\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd19b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www-genesis.destatis.de/genesisWS/rest/2020/helloworld/whoami\"\n",
    "response = requests.get(url)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16db88e",
   "metadata": {},
   "source": [
    "Read about the `logincheck` method (in Section 2.2). Do you have to authenticate? What does it return? Construct a request object using string formatting, send a `request` (in English language) and print the request's status. What type is the response's `text` attribute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d2759",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www-genesis.destatis.de/genesisWS/rest/2020/helloworld/logincheck?username={}&password={}&language={}'.format(genesis_config.Username, genesis_config.Password, 'en')\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d037ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2eb210",
   "metadata": {},
   "source": [
    "Now that we have a working connection to the GENESIS Online API we want to directly obtain an economic indicator, the private sector's savings rate on a quarterly basis, for instance. This `data` is usually stored in a `table` somewhere in the depths of a data warehouse and it is (unfortunately) necessary to familiarise yourself, at least partially, with the internal server's structure.\n",
    "1. In the documentation file search for the `tablefile` method (under Section 2.5 Data). When should it be used? What does it return?\n",
    "2. Which method should you use if you want to directly obtain a `chart`?\n",
    "3. Which method should you use if you want to directly obtain a regional `map`? Which parameter controls the image's resolution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e584e002",
   "metadata": {},
   "outputs": [],
   "source": [
    "field = '12411-0010'\n",
    "stand = '31.12.2019'\n",
    "language = 'en'\n",
    "url = 'https://www-genesis.destatis.de/genesisWS/rest/2020/data/map2table?username={}&password={}&name={}&area=all&mapType=0&classes=5&classification=0&zoom=3&startyear=&endyear=&timeslices=&regionalvariable=&regionalkey=&classifyingvariable1=&classifyingkey1=&classifyingvariable2=&classifyingkey2=&classifyingvariable3=&classifyingkey3=&format=png&stand={}&language={}'.format(genesis_config.Username, genesis_config.Password, field, stand, language)\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07e934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"map.png\", 'wb') as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0b383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='map.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57138740",
   "metadata": {},
   "source": [
    "4. Login to the [GENESIS Online user interface](https://www-genesis.destatis.de/genesis/online?Menu=Anmeldung#abreadcrumb). Familiarise yourself with the tables' structure and navigate to the National Accounts (at the central level) --> Private sector disposable income and savings at quarterly frequency. Which parameters in the request can you control?\n",
    "5. Which method would you choose if you want to directly obtain a `table` in some machine readable format, e.g. a `.csv` or `.xlsx` that you can read into `pandas`? How do you include additional conditions matching particular values?\n",
    "6. Construct a `request` which contains the following specification:\n",
    "    - only seasonally and calendar-adjusted values (X13)\n",
    "    - all available years and quarters\n",
    "    - output format should be a `.xlsx` file\n",
    "7. Send the request but directly through the `pandas.read_excel()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5784a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ce05ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = '81000-0010'\n",
    "key_1 = 'WERT04'\n",
    "val_1 = 'X13JDKSB'\n",
    "key_2 = ''\n",
    "val_2 = ''\n",
    "key_3 = ''\n",
    "val_3 = ''\n",
    "start_year = '1991'\n",
    "end_year = '2020'\n",
    "\n",
    "url = ('https://www-genesis.destatis.de/genesisWS/rest/2020/data/tablefile?username={}&password={}&name={}&area=DINSG*&compress=false&transpose=false&startyear={}&endyear={}&timeslices=&regionalvariable=&regionalkey=&classifyingvariable1={}&classifyingkey1={}&classifyingvariable2={}&classifyingkey2={}&classifyingvariable3={}&classifyingkey3={}&format=xlsx&job=false&stand=&language=de').format(genesis_config.Username, genesis_config.Password, code, start_year, end_year, key_1, val_1, key_2, val_2, key_3, val_3)\n",
    "df = pd.read_excel(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30118f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1936e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa85fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[[2,3,37], :].T.iloc[2:,:]\n",
    "df.columns = ['Year', 'Quarter', 'Rate']\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "df['Year'] = df['Year'].fillna(method='ffill')\n",
    "df['Quarter_str'] = df['Quarter'].copy()\n",
    "df['Quarter'] = df['Quarter'].replace('1. Quartal', 'Q1')\n",
    "df['Quarter'] = df['Quarter'].replace('2. Quartal', 'Q2')\n",
    "df['Quarter'] = df['Quarter'].replace('3. Quartal', 'Q3')\n",
    "df['Quarter'] = df['Quarter'].replace('4. Quartal', 'Q4')\n",
    "df['Rate'] = df['Rate'].replace ('...', np.NaN)\n",
    "qs = df['Year'] + '-' + df['Quarter']\n",
    "df['Date'] = pd.PeriodIndex(qs.values, freq='Q').to_timestamp()\n",
    "df.set_index(df['Date'], inplace = True, drop = True)\n",
    "del df['Date']\n",
    "df.dropna(inplace=True)\n",
    "df['col_name'] = df['Quarter'] + ' ' + df['Year'].str[2:4]\n",
    "col_names = list(df['col_name'].values)\n",
    "df = df.T\n",
    "df.columns = col_names\n",
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb8c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c1a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[\n",
    "    \n",
    "    go.Scatter(name='Private sector savings rate', x = list(df.index),\n",
    "    y = list(df['Rate']))\n",
    "    \n",
    "])\n",
    "\n",
    "fig.layout.update(title = go.layout.Title(\n",
    "                        text='Private sector savings rate (Germany)'))\n",
    "\n",
    "fig.layout.update(yaxis= go.layout.YAxis(title=go.layout.yaxis.Title(\n",
    "                        text='in % of disposable income')))\n",
    "\n",
    "fig.layout.update(xaxis = go.layout.XAxis(title = go.layout.xaxis.Title(text = 'Quarter-Year'), rangeslider = dict(visible = True)));\n",
    "\n",
    "iplot(fig, filename = 'savings_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977fa2f4",
   "metadata": {},
   "source": [
    "## Twitter API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4823f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-twitter --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aba8d5",
   "metadata": {},
   "source": [
    "Note there are [rate limits](https://developer.twitter.com/en/docs/twitter-api/rate-limits)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1094988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "import twitter_config\n",
    "\n",
    "api = twitter.Api(consumer_key = twitter_config.api_key ,\n",
    "                  consumer_secret = twitter_config.api_secret_key,\n",
    "                  access_token_key = twitter_config.access_token,\n",
    "                  access_token_secret = twitter_config.access_token_secret,\n",
    "                  tweet_mode = 'extended',\n",
    "                  sleep_on_rate_limit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ffcca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "got = api.GetSearch('#gameofthrones',\n",
    "                       count = 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76594ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_tweet = got[0]\n",
    "type(example_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3072f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('id:', example_tweet.id)\n",
    "print('Text:', example_tweet.full_text) # key 'text' wenn tweet_mode != 'extended'\n",
    "print('Hashtags:', example_tweet.hashtags)\n",
    "print('Media:', example_tweet.media)\n",
    "print('Date:', example_tweet.created_at)\n",
    "print('Language:', example_tweet.lang)\n",
    "print('Retweets:', example_tweet.retweet_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d512ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tweepy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a001afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78ba852",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(twitter_config.api_key, twitter_config.api_secret_key)\n",
    "auth.set_access_token(twitter_config.access_token, twitter_config.access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4d3933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# searchTerms = \"#maskenaffaere\"\n",
    "noOfSearch = 200\n",
    "searchCountry = \"Germany\"\n",
    "places = api.geo_search(query=searchCountry, granularity=\"country\")\n",
    "place_id = places[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c393e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3dc13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = None\n",
    "for j in range(50):\n",
    "    \n",
    "    header = {\n",
    "        # \"q\": f'{searchTerms} place:{place_id}'.format(searchTerms, place_id) and (\"place:%s\" % place_id),\n",
    "        # \"q\": \"#maskenaffaere -filter:locations\",\n",
    "        # \"q\": \"#maskenaffaere filter:geo_enabled\",\n",
    "        # \"q\": \"#maskenaffaere\",\n",
    "        # \"geocode\": '51.590556,10.106111,310mi',\n",
    "        \"q\": \"place:fdcd221ac44fa326\",\n",
    "        \"lang\": \"de\",\n",
    "        \"tweet_mode\": \"extended\",\n",
    "        \"count\": 100,\n",
    "        \"max_id\": max_id\n",
    "        # \"search_term\": \"\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        batch_tweets = tweepy.Cursor(api.search, **header).items(noOfSearch)\n",
    "        \n",
    "    except Exception as error:\n",
    "        \n",
    "        break\n",
    "        \n",
    "    batch_tweets = [i._json for i in batch_tweets]\n",
    "    batch_ids = [i[\"id\"] for i in batch_tweets]\n",
    "    with open(f'{j}_de_bunch.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(batch_tweets, f, ensure_ascii=False)\n",
    "    max_id = batch_ids[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9f7617",
   "metadata": {},
   "outputs": [],
   "source": [
    "bunches = []\n",
    "\n",
    "for bunch in range(50):\n",
    "    \n",
    "    with open('./Twitter Bunches/' + str(bunch) + '_de_bunch.json', 'r', encoding='utf-8') as f:\n",
    "    \n",
    "        D_read = json.load(f)\n",
    "        bunches.extend(D_read) # extend instead of append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63637025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea196a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_ids = []\n",
    "\n",
    "for tweet in bunches:\n",
    "    \n",
    "    tweet_ids.append(tweet['id'])\n",
    "    \n",
    "len(np.unique(np.array(tweet_ids))), len(bunches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba881865",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = { tweet['id'] : tweet for tweet in bunches } # a dictionary comprehension, dicts do not allow duplicate keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b8173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "\n",
    "for (key, value) in unique.items():\n",
    "    \n",
    "    newDict = dict()\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        if value['place']['bounding_box']['coordinates'] != None:\n",
    "            \n",
    "            newDict[key] = value\n",
    "            \n",
    "            matches.append(newDict)\n",
    "    except:\n",
    "        \n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f841014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "\n",
    "for i in matches:\n",
    "    \n",
    "    empty_dict = {}\n",
    "    \n",
    "    empty_dict['Tweet ID'] = list(i.keys())[0]\n",
    "    \n",
    "    values_list = list(i.values())[0]\n",
    "    \n",
    "    empty_dict['Created at'] = pd.to_datetime(values_list['created_at'])\n",
    "    empty_dict['Full Text'] = values_list['full_text']\n",
    "    empty_dict['User Name'] = values_list['user']['name']\n",
    "    empty_dict['User Alias'] = values_list['user']['screen_name']\n",
    "    empty_dict['Place ID'] = values_list['place']['id']\n",
    "    empty_dict['Place Name'] = values_list['place']['name']\n",
    "    empty_dict['Country Code'] = values_list['place']['country_code']\n",
    "    empty_dict['Country Name'] = values_list['place']['country']\n",
    "    empty_dict['Bounding Box'] = values_list['place']['bounding_box']['coordinates'][0]\n",
    "    \n",
    "    \n",
    "    bbox = Polygon(values_list['place']['bounding_box']['coordinates'][0])\n",
    "    \n",
    "    latitude = bbox.centroid.xy[1][0]\n",
    "    longitude = bbox.centroid.xy[0][0]\n",
    "    \n",
    "    coord = Point(latitude, longitude)\n",
    "    \n",
    "    empty_dict['Tweet Coordinates'] = coord\n",
    "    empty_dict['Retweet Count'] = values_list['retweet_count']\n",
    "    empty_dict['Favorite Count'] = values_list['favorite_count']\n",
    "     \n",
    "    empty_dict['User Location'] = values_list['user']['location']\n",
    "    empty_dict['User Followers'] = values_list['user']['followers_count']\n",
    "    empty_dict['User Friends'] = values_list['user']['friends_count']\n",
    "    empty_dict['Registration Date'] = values_list['user']['created_at']\n",
    "    \n",
    "    tweet_url = 'https://twitter.com/{}/status/{}'.format(values_list['user']['screen_name'], values_list['id'])\n",
    "    empty_dict['Tweet URL'] = tweet_url\n",
    "    \n",
    "    results_list.append(empty_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a0c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d60e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(results_df, geometry=results_df['Tweet Coordinates'])\n",
    "gdf = gdf.set_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a3a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62e3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapbox_access_token = open(\"mapbox_token.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d68e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    go.Scattermapbox(\n",
    "    lat = gdf['geometry'].x.values,\n",
    "    lon = gdf['geometry'].y.values,\n",
    "    mode = 'markers',\n",
    "    marker = go.scattermapbox.Marker(\n",
    "    size = 3.5,\n",
    "    color='red',\n",
    "    #symbol = 'ferry'\n",
    "    ),\n",
    "    text = gdf['Place Name'],\n",
    "    #text = \"Vessel name: <em> \" + df.Name + \"</em><br>\" + \n",
    "    #    \"Destination Port: \" + df.Destination_Port + \"<br>\" +\n",
    "    #    \"Dead weight tonnage: \" + df.DWT.astype(str) + \" tons\"\n",
    "    #text = 'Vessel name = ' + str(df.Name) + ', Dead weight tonnage: ' + str(df.DWT) + 'm³',\n",
    "    )\n",
    "]\n",
    "\n",
    "layout = go.Layout(\n",
    "    autosize=True,\n",
    "    hovermode='closest',\n",
    "    width = 800, \n",
    "    height = 800,\n",
    "    mapbox=go.layout.Mapbox(\n",
    "        accesstoken=mapbox_access_token,\n",
    "        bearing=0,\n",
    "        center=go.layout.mapbox.Center(\n",
    "            lat=51,\n",
    "            lon=10\n",
    "        ),\n",
    "        pitch=0,\n",
    "        zoom=5\n",
    "    ),\n",
    ")\n",
    "                  \n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "iplot(fig, filename=\"geomap_twitter_neu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68c103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chart_studio\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly_config\n",
    "\n",
    "chart_studio.tools.set_credentials_file(username=plotly_config.Username, api_key=plotly_config.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e69ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "py.plot(fig, filename = 'tweets_germany', auto_open = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea4fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec451b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45019d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_data = {'lat': gdf['geometry'].x, 'lon': gdf['geometry'].y}\n",
    "coordinates_df = pd.DataFrame(data=coordinates_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f549e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd = []\n",
    "\n",
    "for i in range(2, 20):\n",
    "    # Find clusters\n",
    "    km = MiniBatchKMeans(n_clusters=i)\n",
    "    km.fit_predict(coordinates_df)\n",
    "    \n",
    "    # Label cluster centers\n",
    "    centers = km.cluster_centers_\n",
    "    \n",
    "    # Calculate sum of squared distances\n",
    "    ssd.append(km.inertia_)\n",
    "    \n",
    "    # Get cluster center\n",
    "    coordinates_df['cluster'] = km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eff48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(2,20), ssd)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "\n",
    "# seems like 5 clusters are appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f1c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del coordinates_df['cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8be2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_clusters = range(2, 20)\n",
    "\n",
    "X = np.array(coordinates_df)\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    \n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    \n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "    \n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ed6128",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = KMeans(n_clusters=11, random_state=10)\n",
    "cluster_labels = clusterer.fit_predict(X)\n",
    "centers = clusterer.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['Cluster Label'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03189e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_gdf = gpd.GeoDataFrame(centers, geometry=[Point(point) for point in centers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39baf29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41145dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "palette = sns.color_palette(None, 11).as_hex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b90edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = palette\n",
    "\n",
    "traces = []\n",
    "\n",
    "for cluster_num in set(cluster_labels):\n",
    "    \n",
    "    sub_df = gdf[gdf['Cluster Label'] == cluster_num]\n",
    "    \n",
    "    trace = go.Scattermapbox(\n",
    "    lat = sub_df['geometry'].x.values,\n",
    "    lon = sub_df['geometry'].y.values,\n",
    "    mode = 'markers',\n",
    "    marker = go.scattermapbox.Marker(\n",
    "    size = 5,\n",
    "    color= colors[cluster_num],\n",
    "    #symbol = 'star'\n",
    "    ),\n",
    "    text = sub_df['Place Name'] + \"<br>\" +\n",
    "        \"Cluster ID: \" + str(cluster_num)\n",
    "    )\n",
    "    \n",
    "    traces.append(trace)\n",
    "    \n",
    "cluster_center_trace = go.Scattermapbox(\n",
    "    lat = centers_gdf['geometry'].x.values,\n",
    "    lon = centers_gdf['geometry'].y.values,\n",
    "    mode = 'markers',\n",
    "    marker = go.scattermapbox.Marker(\n",
    "    size = 7,\n",
    "    color='red',\n",
    "    #symbol = 'star'\n",
    "    ),\n",
    "    text = list(range(7))\n",
    "    )\n",
    "\n",
    "traces.append(cluster_center_trace)\n",
    "    \n",
    "fig = go.Figure(data = traces)\n",
    "\n",
    "layout = go.Layout(\n",
    "    autosize=True,\n",
    "    hovermode='closest',\n",
    "    width = 800, \n",
    "    height = 800,\n",
    "    mapbox=go.layout.Mapbox(\n",
    "        accesstoken=mapbox_access_token,\n",
    "        bearing=0,\n",
    "        center=go.layout.mapbox.Center(\n",
    "            lat=51,\n",
    "            lon=10\n",
    "        ),\n",
    "        pitch=0,\n",
    "        zoom=5\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.layout.update(layout)\n",
    "                  \n",
    "iplot(fig, filename=\"geomap_twitter_cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# germany_borders = gpd.read_file(\"Bundeslaender_2016_ew.shp\")\n",
    "# You can find it here: https://opendata-esri-de.opendata.arcgis.com/datasets/b8d0cc7735774bed8e6df1c5410394a4_0?geometry=-31.360%2C46.270%2C52.268%2C55.886"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0394ef39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d217dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = ['Dexit', '#Dexit']\n",
    "\n",
    "match_index = []\n",
    "\n",
    "for i in range(len(results_df)):\n",
    "    \n",
    "    element = results_df.iloc[i]\n",
    "    \n",
    "    if any(hashtag in element['Full Text'] for hashtag in hashtags):\n",
    "    \n",
    "        print(\"Match found!\")\n",
    "        \n",
    "        match_index.append(i)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8495ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = results_df[results_df.index.isin(match_index)]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff00f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(filtered_df, geometry=filtered_df['Tweet Coordinates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4b3f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=go.Scattergeo(\n",
    "        lon = gdf['geometry'].y.values,\n",
    "        lat = gdf['geometry'].x.values,\n",
    "        text = gdf['Place Name'],\n",
    "        mode = 'markers'\n",
    "        ))\n",
    "\n",
    "fig.update_layout(\n",
    "        title = \"Tweets regarding '#Dexit' in Germany\",\n",
    "        geo_scope='europe',\n",
    "    )\n",
    "\n",
    "iplot(fig, filename =\"geomap_twitter\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Webscraping Workshop",
   "language": "python",
   "name": "webscraping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
